{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><h1>Building Model</h1></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras                                     # importing keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using Transfer learning And Fine tunning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Transfer learning is a method where a model developed for a task is reused as the starting point for a model on a second task.\n",
    "<br></br>\n",
    "<br></br>\n",
    "It is a popular approach in deep learning where pre-trained models are used as the starting point on computer vision and natural language processing tasks given the vast compute and time resources required to develop neural network models on these problems and from the huge jumps in skill that they provide on related problems.\n",
    "<br></br>\n",
    "<br></br>\n",
    "<i>Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned.</i>\n",
    "<br></br>\n",
    "<br></br>\n",
    "In Fine-Tuning we optimize both the weights of the new classification layers we have added, as well as some or all of the layers from the model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224                          # Input image size\n",
    "channels = 3                            # For Gray image channel will be 1. For RGB it's image 3\n",
    "Classes = [\"Black\", \"White\"]            # Class labels \n",
    "\n",
    "def model():\n",
    "    \n",
    "    from keras.applications.mobilenet import MobileNet\n",
    "    #from keras.applications.inception_v3 import InceptionV3\n",
    "    #from keras.applications.vgg19 import VGG19\n",
    "    #from keras.applications.resnet50 import ResNet50\n",
    "    \n",
    "    base_model = keras.applications.mobilenet.MobileNet(weights = \"imagenet\",include_top = False, input_shape = (img_size,img_size,channels))\n",
    "    #base_model = keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape = (img_size, img_size, channels))\n",
    "    #base_model = keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape = (img_size, img_size, channels))\n",
    "    #base_model = keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape = (img_size, img_size, channels))\n",
    "    \n",
    "    \n",
    "    # for more models checkout https://keras.io/applications/\n",
    "    \n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "    # Add Or Modify layers here\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)                                               # before adding FC layer, we have to flatten our input\n",
    "    x = Dense(64, activation = \"relu\")(x)                          # Adding fully_connected(FC) layer of 24 nodes\n",
    "    x = Dropout(0.2)(x)                                            # 20% neurons dropped-out randomly, during training\n",
    "    x = Dense(64, activation = \"relu\")(x)\n",
    "    \n",
    "    #___________\n",
    "    predictions = Dense(len(Classes), activation = \"softmax\")(x)\n",
    "    \n",
    "    from keras.models import Sequential, Model\n",
    "\n",
    "    Model = Model(input = base_model.input, output = predictions)\n",
    "    Model.summary()\n",
    "    return Model\n",
    "\n",
    "\n",
    "Model = model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Flatten</b> - Flattening is converting n-dimensional array into 1 dimensional.\n",
    "                 <a href = \"https://www.google.com/imgres?imgurl=https%3A%2F%2Fsds-platform-private.s3-us-east-2.amazonaws.com%2Fuploads%2F73_blog_image_1.png&imgrefurl=https%3A%2F%2Fwww.superdatascience.com%2Fblogs%2Fconvolutional-neural-networks-cnn-step-3-flattening&docid=c7wpEZBc90Q8tM&tbnid=Rmtg_AgwhISrIM%3A&vet=10ahUKEwjUrOmo6q3kAhWSfCsKHf6YBKIQMwhIKAAwAA..i&w=866&h=414&bih=754&biw=1536&q=flattening%20data%20in%20ml&ved=0ahUKEwjUrOmo6q3kAhWSfCsKHf6YBKIQMwhIKAAwAA&iact=mrc&uact=8\">Example of Flattening</a>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<b>Dropout </b>- Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. You can imagine that if neurons are randomly dropped out of the network during training, that other neurons will have to step in and handle the representation required to make predictions for the missing neurons. The effect is that the network becomes less sensitive to the specific weights of neurons. This in turn results in a network that is capable of better generalization and is less likely to overfit the training data.\n",
    "<br></br>\n",
    "<br></br>\n",
    "<b>Dense </b>- A dense layer is a classic fully connected(FC) neural network layer : each input node is connected to each output node. <a href=\"https://www.google.com/imgres?imgurl=https%3A%2F%2Fcdn-images-1.medium.com%2Fmax%2F600%2F1*yjy3dwRL-vmSpmUG7UNJYg%402x.png&imgrefurl=https%3A%2F%2Fmc.ai%2Ffully-connected-layer-with-dynamic-input-shape%2F&docid=qt9by3vvOqmxUM&tbnid=L-uPROr6BWZOMM%3A&vet=10ahUKEwi_hrLS6a3kAhWZaCsKHfP5C2YQMwiFASgRMBE..i&w=441&h=538&bih=754&biw=1536&q=fully%20connected%20layer%20image&ved=0ahUKEwi_hrLS6a3kAhWZaCsKHfP5C2YQMwiFASgRMBE&iact=mrc&uact=8\">Example of Fully Connected layer</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(Model):\n",
    "    from keras.models import load_model\n",
    "    \n",
    "    # Saving whole models (architecture + weights + optimizer state)\n",
    "    filename = \"Model.h5\"                                                          #file name\n",
    "    Model.save(filename)  # creates a HDF5 file 'Model.h5'\n",
    "    print(filename, \"has been Saved.\")\n",
    "\n",
    "save_model(Model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
