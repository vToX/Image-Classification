{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><h1>Preprocessing</h1></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data preprocessing is an integral step in Image Classification as the quality of data and the useful information that can be derived from it directly affects the ability of our model to learn. Therefore, it is extremely important that we preprocess our data before feeding it into our model.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224                                                                #input image size\n",
    "Channels = 3                                                                  #for Gray image channel will be 1. For RGB image its 3\n",
    "Data_Path = \"C:/Users/Rahul Patil/Desktop/Ganesh/Keras Practice/BandW data/\"  # Path to your Database\n",
    "                                                                              # have a look \n",
    "                                                                              # \"\"\"\n",
    "                                                                              #      --- BandW data\n",
    "                                                                              #    |    |--- cat\n",
    "                                                                              #    |    |    |--- 00000000.jpg\n",
    "                                                                              #    |    |    |--- 00000001.jpg\n",
    "\n",
    "                                                                              #    |    |    |--- 00000460.jpg\n",
    "                                                                              #    |    |--- dog\n",
    "                                                                              #    |    |    |--- 00000000.jpg\n",
    "                                                                              #    |    |    |--- 00000001.jpg\n",
    "\n",
    "                                                                              #    |    |    |--- 00000460.jpg\n",
    "\n",
    "                                                                              #  \"\"\"\n",
    "\n",
    "Classes = ['Black', 'White']                                                  # Class labels \n",
    "\n",
    "def Read_Data(Data_Path, Classes, img_size, Channels):\n",
    "    import os\n",
    "    import cv2\n",
    "    \n",
    "    Data = []\n",
    "    for Class in Classes:\n",
    "        Path = os.path.join(Data_Path, Class)\n",
    "        class_num = Classes.index(Class)\n",
    "        \n",
    "        for img in os.listdir(Path):\n",
    "            \n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(Path, img), -1)\n",
    "                \n",
    "                if Channels == 1:\n",
    "                    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "                resize_img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                \n",
    "                Data.append([resize_img_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return Data\n",
    "\n",
    "Data = Read_Data(Data_Path, Classes, img_size, Channels)\n",
    "print(\"length of Database is\",  len(Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Shuffle Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Shuffling data serves the purpose of reducing variance and making sure that models remain general and overfit less.\n",
    "You have to shuffle to make sure that your training/test sets are representative of the overall distribution of the data.\n",
    "Shuffle data is also imporatant for each <i>epoch</i> to have different data for each <I>batch</i>.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Epoch</b> - Epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
    "<br></br>\n",
    "<b>Batch</b> - During the learning and optimization process, instead of loading all the training dataset at once, they are loaded in sets of specific size. These sets are called batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shuffle_Data(Data):\n",
    "    import random\n",
    "    random.shuffle(Data)\n",
    "    print(\"Data shuffled sucessefully.\")\n",
    "    return Data\n",
    "\n",
    "Data = Shuffle_Data(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalize</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Normalization is used to bring features in a dataset to the same scale. When you normalize a feature, all feature values will be in the range of 0 to 1.\n",
    "Normalization is defined as the process of rescaling original data without changing its behavior or nature.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(Data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    for x, y in Data:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "    X = np.array(X) / 255\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X, Y = Normalization(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Reshape</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Reshape is important to convert data into keras acceptable/recognizable shape</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reshape(X, Y):\n",
    "    import numpy as np\n",
    "    \n",
    "    X = np.array(X).reshape(-1, img_size, img_size, Channels)\n",
    "    \n",
    "    from keras.utils import np_utils\n",
    "    Y = np_utils.to_categorical(Y, len(Classes))\n",
    "    \n",
    "    print(\"X shape : \", X.shape)\n",
    "    print(\"Y shape : \", Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = Reshape(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preprocessing is long and hectic process, and also we don't want to this noobie stuff again and again. Therefore saving data is Must.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_Data(X, Y):\n",
    "    import pickle\n",
    "    \n",
    "    pickle_out = open('X.pickle', 'wb')\n",
    "    pickle.dump(X, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    pickle_out = open('Y.pickle', 'wb')\n",
    "    pickle.dump(Y, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    print(\"Data Saved Sucessesfully.\")\n",
    "\n",
    "Save_Data(X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
